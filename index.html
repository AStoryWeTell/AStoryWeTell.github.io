<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
<font face="verdana, Sans-serif">
<head>
   <style>
       .indent-block {
           padding-left: 2em; /* indentation for blocks */
       }
   </style>
  <title>A Story We Tell</title>
</head>


<body  bgcolor="white" link="maroon" vlink="darkred" alink="darkred">

<table>
  <tbody>
    <tr>
      <td bgcolor="maroon" width="30">&nbsp;</td>
      
      <td bgcolor="darkred" width="1">&nbsp;</td>
      <td bgcolor="white" width="10">&nbsp;</td>

      <td width="15"> 
      <td>
	<h1 style="color: darkred">Is Consciousness a Story We Tell Ourselves?</h1>
	<h2 style="color: darkred">Internal language and consciousness after chain of thought reasoning.</h2>
  <table>
    <tbody>
      <tr>
	<td><img src="./WittgensteinHouseSmall.jpg" type="image/jpeg" style="max-width:200px;" alt="Wittgenstein House in Vienna" /></td>
	<td width="30"></td>
	<td>
<p><b>Where and when?</b></p>
<blockquote>
  A Symposium at the <b>AISB Convention 2026</b><br>
  <a href="https://aisb.org.uk/aisb-convention-2026/">aisb.org.uk/aisb-convention-2026</a><br>
  <p><br></p>
    1-2 July 2026<br>
    University of Sussex, Brighton, UK<br>
  <p><br></p>
      <b>Hosted by</b><br> The Society for the study of Artificial Intelligence and Simulation of Behaviour<br>
</p>
</blockquote>
	</td>
    </tbody>
  </table>
<p><br></p>

<p><b>Key dates</b></p>

<p>There will be a call for contributed talks; the date will be announced shortly.</p>

<p><b>Description</b></p>

<p>Consciousness may arise from, or be structured by, our ability to access and reason about internal representations through the internal use of language. This half-day symposium will address the question: “Is consciousness a story we tell ourselves?” by examining the relationship between consciousness, inner speech in humans and chain-of-thought reasoning in machines. Many theories of consciousness assume some role for internal representations, but articulate this in different ways: as higher-order thoughts, global workspace broadcasts, predictive processing hierarchies, or self-model mechanisms. However, language has often been treated as secondary. This is surprising: although language is most obviously a tool for communication, it also scaffolds thought and provides the structured, sequential space in which humans build multi-step inferences, integrate emotions with concepts, and carry out forms of reasoning not found elsewhere in the animal kingdom. Some of the structure of language may itself derive from spatial and causal relations encoded in internal representations; when formalised over discrete symbols, this internal narrative machinery supports inference, planning, and the construction of abstract models. This symposium will explore the possibility that such internalized linguistic processes are not merely adjuncts to cognition but play a constitutive role in conscious experience.</p>

<p>Questions of consciousness have a new urgency because of the recent machine learning revolution. Chain-of-thought reasoning in large language models provides a striking parallel: models become more capable when they are allowed to "talk to themselves", producing extended internal sequences that guide inference. This suggests a manipulable model system in which we can probe the functional role of internal narrative; something far harder to do in humans. It also challenges us to either accept that machine that use chain-of-thought reasoning are consciousness or explain precisely why they are not without reaching for ill-considered ideas about embodiment. Thus chain-of-thought in machines and its parallel to the internal use of language in humans, raises timely and foundational questions about whether language-like internal activity is a neccessary, or even a sufficient, condition for consciousness.</p>

<p>The field lacks an agreed experimental programme capable of discriminating language-centric theories of consciousness from language-minimal ones. Key questions remain unresolved. To what extent can we disrupt inner speech without fragmenting conscious experience? Do perturbations of internal language alter the qualitative structure of experience, rather than merely task performance? And can non-linguistic agents—infants, non-human animals, or artificial systems support forms of consciousness that are functionally or phenomenologically comparable to those of linguistic adults? Most importantly, are any of these questions capable of empirical resolution? What experimental programme do these questions suggest.</p>

<p>The symposium will open with a panel discussion aimed at clarifying central concepts of consciousness and identifying core questions about the relationship between language, thought, and experience. This will be followed by a series of contributed talks presenting empirical, theoretical, and computational perspectives. A concluding panel will focus on the practical challenge of designing discriminating experiments. Its goal will be to identify a set of ``keystone'' experiments and to specify, as precisely as possible, the predictions that competing theories would make.</p>


</td>
  </tbody>
</table>
</body>
</html>




